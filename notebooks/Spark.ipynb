{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlnqvgBhJok_"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s33kQ-IHJqhP",
        "outputId": "d7e8df53-fd51-407c-aa01-7bbd51eedc8a"
      },
      "source": [
        "!wget https://dlcdn.apache.org/spark/spark-3.0.3/spark-3.0.3-bin-hadoop2.7.tgz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-29 00:06:32--  https://dlcdn.apache.org/spark/spark-3.0.3/spark-3.0.3-bin-hadoop2.7.tgz\n",
            "Resolving dlcdn.apache.org (dlcdn.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
            "Connecting to dlcdn.apache.org (dlcdn.apache.org)|151.101.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 220400553 (210M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.0.3-bin-hadoop2.7.tgz’\n",
            "\n",
            "spark-3.0.3-bin-had 100%[===================>] 210.19M   144MB/s    in 1.5s    \n",
            "\n",
            "2021-11-29 00:06:43 (144 MB/s) - ‘spark-3.0.3-bin-hadoop2.7.tgz’ saved [220400553/220400553]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox0VqHu8JsQE"
      },
      "source": [
        "!tar xf /content/spark-3.0.3-bin-hadoop2.7.tgz"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slA4vqwhJtVc"
      },
      "source": [
        "!pip install -q findspark"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPqRO8mSJvYh"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.3-bin-hadoop2.7\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5X2y4FzJwwE"
      },
      "source": [
        "import findspark\n",
        "from pyspark.sql import Row\n",
        "findspark.init(\"/content/spark-3.0.3-bin-hadoop2.7\")# SPARK_HOME\n",
        "from pyspark.sql import SparkSession\n",
        "ss = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "SpContext = ss.sparkContext"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOTs4ll4J5Nn",
        "outputId": "578e4c98-ea30-47e5-f675-5825e4b31ef3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZlrlmp38Fdk",
        "outputId": "b049496e-3e70-4b28-885e-deada0a7945c"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrrnp6XizNMD"
      },
      "source": [
        "PATH = '/content/drive/MyDrive/BigData/dataset\\ proyecto/myfile.csv'\n",
        "df = ss.read.csv(PATH, header=True)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoAB8Goq7CZB",
        "outputId": "b982b692-1fcb-4280-c302-6f50b649fc0a"
      },
      "source": [
        "df = df.select('id', 'labels', 'tweet_text', 'labels_str')\n",
        "df.take(3)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(id='1114679353714016256', labels='[4, 1, 3]', tweet_text='@FriskDontMiss Nigga https://t.co/cAsaLWEpue', labels_str=\"['Religion', 'Racist', 'Homophobe']\"),\n",
              " Row(id='1063020048816660480', labels='[5, 5, 5]', tweet_text='My horses are retarded https://t.co/HYhqc6d5WN', labels_str=\"['OtherHate', 'OtherHate', 'OtherHate']\"),\n",
              " Row(id='1108927368075374593', labels='[0, 0, 0]', tweet_text='“NIGGA ON MA MOMMA YOUNGBOY BE SPITTING REAL SHIT NIGGA” https://t.co/UczofqHrLq', labels_str=\"['NotHate', 'NotHate', 'NotHate']\")]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVa0WnB27Dd8"
      },
      "source": [
        "_stopwords = set(stopwords.words(\"english\") + ['\\'', '’'])\n",
        "\n",
        "def limpiar(row):\n",
        "  t = row['tweet_text']\n",
        "  without_links = ' '.join([word for word in t.split(' ') if word[:4] != 'http']) # quitar los links\n",
        "  tokens = word_tokenize(without_links) # tokenizar (dividir en tokens)\n",
        "  tokens = map(lambda token: token.encode('ascii', 'ignore').decode('ascii'), tokens)\n",
        "  tokens_without_sw = [word.lower() for word in tokens if word.isalpha() and not word in _stopwords]\n",
        "  new_row = Row(id=row['id'], labels=row['labels'], tweet_text=' '.join(tokens_without_sw), labels_str=row['labels_str'])\n",
        "  return new_row"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5QgJG658JsJ",
        "outputId": "f7b4f8a8-182b-4ef3-b2e8-961c45ab4f2d"
      },
      "source": [
        "df_limpio = df.rdd.map(limpiar)\n",
        "df_limpio.take(2)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(id='1114679353714016256', labels='[4, 1, 3]', tweet_text='friskdontmiss nigga', labels_str=\"['Religion', 'Racist', 'Homophobe']\"),\n",
              " Row(id='1063020048816660480', labels='[5, 5, 5]', tweet_text='my horses retarded', labels_str=\"['OtherHate', 'OtherHate', 'OtherHate']\")]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ]
}