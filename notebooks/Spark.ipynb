{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install elephas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget https://dlcdn.apache.org/spark/spark-3.0.3/spark-3.0.3-bin-hadoop2.7.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!tar xf /content/spark-3.0.3-bin-hadoop2.7.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.3-bin-hadoop2.7\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5X2y4FzJwwE"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSmxlOkfPDG9"
      },
      "outputs": [],
      "source": [
        "ss = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "SpContext = ss.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZlrlmp38Fdk",
        "outputId": "825c8aba-e29b-45cd-e984-d4201110ad8e"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrrnp6XizNMD"
      },
      "outputs": [],
      "source": [
        "PATH = '/content/drive/MyDrive/BigData/dataset\\ proyecto/myfile.csv'\n",
        "df = ss.read.csv(PATH, header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoAB8Goq7CZB",
        "outputId": "5492daf5-961a-498e-feb5-8e2e94816f3a"
      },
      "outputs": [],
      "source": [
        "df = df.select('id', 'labels', 'tweet_text', 'labels_str')\n",
        "df.take(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVa0WnB27Dd8"
      },
      "outputs": [],
      "source": [
        "_stopwords = set(stopwords.words(\"english\") + ['\\'', 'â€™'])\n",
        "\n",
        "def limpiar(row):\n",
        "  t = row['tweet_text']\n",
        "  without_links = ' '.join([word for word in t.split(' ') if word[:4] != 'http']) # quitar los links\n",
        "  tokens = word_tokenize(without_links) # tokenizar (dividir en tokens)\n",
        "  tokens = map(lambda token: token.encode('ascii', 'ignore').decode('ascii'), tokens)\n",
        "  tokens_without_sw = [word.lower() for word in tokens if word.isalpha() and not word in _stopwords]\n",
        "  new_row = Row(id=row['id'], labels=row['labels'], tweet_text=' '.join(tokens_without_sw), labels_str=row['labels_str'])\n",
        "  return new_row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5QgJG658JsJ",
        "outputId": "3037ba86-f162-41e6-cc7d-48d297e1911f"
      },
      "outputs": [],
      "source": [
        "df_limpio = df.rdd.map(limpiar)\n",
        "df_limpio.take(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-KBDZhqDEX5"
      },
      "outputs": [],
      "source": [
        "def input_texts(row):\n",
        "  labels_list = row['labels']\n",
        "  label = max(set(labels_list), key = labels_list.count)\n",
        "  if label == ' ' or label == '[':\n",
        "    label = 1\n",
        "  if int(label) > 0:\n",
        "    label = 1\n",
        "  return Row(row['tweet_text'], str(label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_tP22w3DoRi",
        "outputId": "d80b765a-4932-46fd-f96d-216a94aecbcf"
      },
      "outputs": [],
      "source": [
        "rdd_rows = df_limpio.map(input_texts)\n",
        "columns = [\"tweets\",\"labels\"]\n",
        "rdd_df = ss.createDataFrame(rdd_rows).toDF(*columns)\n",
        "rdd_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tweetValues = rdd_df.select('tweets').rdd.flatMap(lambda x: x).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIPlUnXusaCJ"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# The maximum number of words to be used. (most frequent)\n",
        "MAX_NB_WORDS = 100\n",
        "# Max number of words in each complaint.\n",
        "MAX_SEQUENCE_LENGTH = 5\n",
        "# This is fixed.\n",
        "EMBEDDING_DIM = 100\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(tweetValues)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxOmaLL5uqaz",
        "outputId": "c81618ad-6cb0-4758-e316-72d0a7723d44"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X = tokenizer.texts_to_sequences(tweetValues)\n",
        "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBNqk9lTu0Fd",
        "outputId": "6e9c313d-cb1f-43f7-bce9-52b6d8378573"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "Y = pd.get_dummies(rdd_df.select('labels').rdd.flatMap(lambda x: x).collect())\n",
        "print('Shape of label tensor:', Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JAWnkDb0T1b",
        "outputId": "7f308c8f-5660-4ae2-9770-c3510e460ca2"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.10, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQh76GSR0lvu",
        "outputId": "19a7c7c3-47e9-4216-eba6-5ed525f5d3f4"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install systemml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from systemml.mllearn import Keras2DML\n",
        "import math\n",
        "\n",
        "epochs = 5\n",
        "batch_size = 64\n",
        "samples = 134840\n",
        "max_iter = int(epochs*math.ceil(samples/batch_size))\n",
        "sysml_model = Keras2DML(ss, model, input_shape=(1,28,28), weights='weights_dir', batch_size=batch_size, max_iter=max_iter, test_interval=0, display=10)\n",
        "sysml_model.fit(X_train, Y_train)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "LSTM Spark.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
