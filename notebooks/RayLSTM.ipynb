{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RayLSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjoRcWQvVnJl",
        "outputId": "28fa8c5b-ef7d-409d-f581-839bd8141c26"
      },
      "source": [
        "!pip install ray"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ray in /usr/local/lib/python3.7/dist-packages (1.9.0)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray) (1.42.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.17.3)\n",
            "Requirement already satisfied: redis>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ray) (4.0.2)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.19.5)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.3)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray) (21.2.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (2.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (3.13)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.28.1->ray) (1.15.0)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray) (1.2.13)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated->redis>=3.5.0->ray) (1.13.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jovian"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3RqIq3lAi4P",
        "outputId": "f683b534-482f-49cd-9787-9a6e47484db5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jovian in /usr/local/lib/python3.7/dist-packages (0.2.41)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from jovian) (3.13)\n",
            "Requirement already satisfied: uuid in /usr/local/lib/python3.7/dist-packages (from jovian) (1.30)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from jovian) (2.23.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from jovian) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->jovian) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->jovian) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->jovian) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->jovian) (2021.10.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#library imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import spacy\n",
        "import jovian\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import string\n",
        "import ray.train as train\n",
        "from ray.train import Trainer\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "Tw5AqpgjAqvn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sR5IPRsHV0zm",
        "outputId": "05fccbb5-1edb-484e-e1dc-18f9e504fd92"
      },
      "source": [
        "import ray\n",
        "ray.init(num_cpus=8)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'metrics_export_port': 55625,\n",
              " 'node_id': 'f203303f9abe63f5702c9edd583603cb40e4eeae11dad240ab745ad7',\n",
              " 'node_ip_address': '172.28.0.2',\n",
              " 'object_store_address': '/tmp/ray/session_2021-12-09_02-09-38_381968_3890/sockets/plasma_store',\n",
              " 'raylet_ip_address': '172.28.0.2',\n",
              " 'raylet_socket_name': '/tmp/ray/session_2021-12-09_02-09-38_381968_3890/sockets/raylet',\n",
              " 'redis_address': '172.28.0.2:6379',\n",
              " 'session_dir': '/tmp/ray/session_2021-12-09_02-09-38_381968_3890',\n",
              " 'webui_url': None}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Myc-KaqQV5rc",
        "outputId": "8fec04ef-04fb-49a8-cc52-7f660b4f69ad"
      },
      "source": [
        "from json import load\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ug3f9ia7WFPR",
        "outputId": "2c61f124-1539-4258-c0db-5424d8727a60"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VldC2C6HWUFm"
      },
      "source": [
        "PATH ='/content/drive/MyDrive/BigData/'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls /root/ray_results/train_2021-12-09_02-18-44/run_001"
      ],
      "metadata": {
        "id": "C-ZrWTX4PJQW"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_XYS8MIWVSo"
      },
      "source": [
        "with open(PATH + '/MMHS150K_GT.json', 'r') as fp:\n",
        "  data = load(fp)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7_J_2tTWgX4"
      },
      "source": [
        "df = pd.DataFrame.from_dict(data, orient='index')\n",
        "\n",
        "df = df[['tweet_text', 'labels', 'tweet_url']]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['tweet_text'] = df['tweet_text'] + ' ' + df['tweet_text'] "
      ],
      "metadata": {
        "id": "rqsgHeUZ2vab"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "14V1wTa50hYL",
        "outputId": "e315a12f-9b59-45a0-8259-32b87425d4a6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>labels</th>\n",
              "      <th>tweet_url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1114679353714016256</th>\n",
              "      <td>@FriskDontMiss Nigga https://t.co/cAsaLWEpue @...</td>\n",
              "      <td>[4, 1, 3]</td>\n",
              "      <td>https://twitter.com/user/status/11146793537140...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1063020048816660480</th>\n",
              "      <td>My horses are retarded https://t.co/HYhqc6d5WN...</td>\n",
              "      <td>[5, 5, 5]</td>\n",
              "      <td>https://twitter.com/user/status/10630200488166...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1108927368075374593</th>\n",
              "      <td>“NIGGA ON MA MOMMA YOUNGBOY BE SPITTING REAL S...</td>\n",
              "      <td>[0, 0, 0]</td>\n",
              "      <td>https://twitter.com/user/status/11089273680753...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1114558534635618305</th>\n",
              "      <td>RT xxSuGVNGxx: I ran into this HOLY NIGGA TODA...</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "      <td>https://twitter.com/user/status/11145585346356...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1035252480215592966</th>\n",
              "      <td>“EVERYbody calling you Nigger now!” https://t....</td>\n",
              "      <td>[1, 0, 1]</td>\n",
              "      <td>https://twitter.com/user/status/10352524802155...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                            tweet_text  ...                                          tweet_url\n",
              "1114679353714016256  @FriskDontMiss Nigga https://t.co/cAsaLWEpue @...  ...  https://twitter.com/user/status/11146793537140...\n",
              "1063020048816660480  My horses are retarded https://t.co/HYhqc6d5WN...  ...  https://twitter.com/user/status/10630200488166...\n",
              "1108927368075374593  “NIGGA ON MA MOMMA YOUNGBOY BE SPITTING REAL S...  ...  https://twitter.com/user/status/11089273680753...\n",
              "1114558534635618305  RT xxSuGVNGxx: I ran into this HOLY NIGGA TODA...  ...  https://twitter.com/user/status/11145585346356...\n",
              "1035252480215592966  “EVERYbody calling you Nigger now!” https://t....  ...  https://twitter.com/user/status/10352524802155...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCKlYMzTWzB0"
      },
      "source": [
        "_stopwords = set(stopwords.words(\"english\") + ['\\'', '’'])\n",
        "\n",
        "def limpiar(t):\n",
        "  without_links = ' '.join([word for word in t.split(' ') if word[:4] != 'http']) # quitar los links\n",
        "  tokens = word_tokenize(without_links) # tokenizar (dividir en tokens)\n",
        "  tokens = map(lambda token: token.encode('ascii', 'ignore').decode('ascii'), tokens)\n",
        "  tokens_without_sw = [word.lower() for word in tokens if word.isalpha() and not word in _stopwords]\n",
        "  return ' '.join(tokens_without_sw)\n",
        "\n",
        "@ray.remote\n",
        "def ray_limpiar(t):\n",
        "  return limpiar(t)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL-vwAkuW09S",
        "outputId": "0cad74ba-ff3c-4966-fd2f-ca08fbfbbe29"
      },
      "source": [
        "df['tweet_text'] = df['tweet_text'].map(ray_limpiar.remote)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ray_limpiar pid=4125)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4125)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4041)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4173)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4183)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4125)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4125)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4124)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(ray_limpiar pid=4042)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ray_limpiar pid=4124)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4042)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4125)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4124)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4125)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4125)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4239)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4238)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4125)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4124)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4183)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4042)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(ray_limpiar pid=4042)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4041)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ray_limpiar pid=4041)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4238)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4042)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4239)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(ray_limpiar pid=4125)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ray_limpiar pid=4239)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4124)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4042)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(ray_limpiar pid=4042)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ray_limpiar pid=4183)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4124)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4238)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4238)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4042)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(ray_limpiar pid=4125)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ray_limpiar pid=4042)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4124)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(ray_limpiar pid=4041)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ray_limpiar pid=4183)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4125)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(ray_limpiar pid=4238)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ray_limpiar pid=4042)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(ray_limpiar pid=4173)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ray_limpiar pid=4173)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4239)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(ray_limpiar pid=4183)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ray_limpiar pid=4238)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4173)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4041)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(ray_limpiar pid=4183)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ray_limpiar pid=4124)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4183)\u001b[0m \n",
            "\u001b[2m\u001b[36m(ray_limpiar pid=4042)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(ray_limpiar pid=4183)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ray_limpiar pid=4125)\u001b[0m \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua1xakW-aIUf"
      },
      "source": [
        "df['tweet_text'] = df['tweet_text'].map(ray.get)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w24rbWmw2H4E"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wM4gDMcOX-Fa",
        "outputId": "d52fb95f-7cdd-4390-efc5-4acffcc8bfe7"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>labels</th>\n",
              "      <th>tweet_url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1114679353714016256</th>\n",
              "      <td>friskdontmiss nigga friskdontmiss nigga</td>\n",
              "      <td>[4, 1, 3]</td>\n",
              "      <td>https://twitter.com/user/status/11146793537140...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1063020048816660480</th>\n",
              "      <td>my horses retarded my horses retarded</td>\n",
              "      <td>[5, 5, 5]</td>\n",
              "      <td>https://twitter.com/user/status/10630200488166...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1108927368075374593</th>\n",
              "      <td>nigga on ma momma youngboy be spitting real sh...</td>\n",
              "      <td>[0, 0, 0]</td>\n",
              "      <td>https://twitter.com/user/status/11089273680753...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1114558534635618305</th>\n",
              "      <td>rt xxsugvngxx i ran holy nigga today rt xxsugv...</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "      <td>https://twitter.com/user/status/11145585346356...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1035252480215592966</th>\n",
              "      <td>everybody calling nigger everybody calling nigger</td>\n",
              "      <td>[1, 0, 1]</td>\n",
              "      <td>https://twitter.com/user/status/10352524802155...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                            tweet_text  ...                                          tweet_url\n",
              "1114679353714016256            friskdontmiss nigga friskdontmiss nigga  ...  https://twitter.com/user/status/11146793537140...\n",
              "1063020048816660480              my horses retarded my horses retarded  ...  https://twitter.com/user/status/10630200488166...\n",
              "1108927368075374593  nigga on ma momma youngboy be spitting real sh...  ...  https://twitter.com/user/status/11089273680753...\n",
              "1114558534635618305  rt xxsugvngxx i ran holy nigga today rt xxsugv...  ...  https://twitter.com/user/status/11145585346356...\n",
              "1035252480215592966  everybody calling nigger everybody calling nigger  ...  https://twitter.com/user/status/10352524802155...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenization\n",
        "tok = spacy.load('en')\n",
        "def tokenize (text):\n",
        "    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n",
        "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]') # remove punctuation and numbers\n",
        "    nopunct = regex.sub(\" \", text.lower())\n",
        "    return [token.text for token in tok.tokenizer(nopunct)]"
      ],
      "metadata": {
        "id": "RqxV4KZnNDQR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G_uqWSwZ3TK"
      },
      "source": [
        "counts = Counter()\n",
        "for index, row in df.iterrows():\n",
        "    counts.update(tokenize(row['tweet_text']))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating vocabulary\n",
        "vocab2index = {\"\":0, \"UNK\":1}\n",
        "words = [\"\", \"UNK\"]\n",
        "for word in counts:\n",
        "    vocab2index[word] = len(words)\n",
        "    words.append(word)"
      ],
      "metadata": {
        "id": "Z0rs6MFOM06_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_sentence(text, vocab2index, N=70):\n",
        "    tokenized = tokenize(text)\n",
        "    encoded = np.zeros(N, dtype=int)\n",
        "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized])\n",
        "    length = min(N, len(enc1))\n",
        "    encoded[:length] = enc1[:length]\n",
        "    return encoded, length"
      ],
      "metadata": {
        "id": "5bZXeU7BN_qX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_label(labels):\n",
        "    zeroes_count = 0\n",
        "    for i in labels:\n",
        "      if i == 0:\n",
        "        zeroes_count += 1\n",
        "    if zeroes_count > 1:\n",
        "      return 0\n",
        "    \n",
        "    return 1"
      ],
      "metadata": {
        "id": "tQjSkBJDymKb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['encoded'] = df['tweet_text'].apply(lambda x: np.array(encode_sentence(x,vocab2index )))\n",
        "df['targer_label'] = df['labels'].apply(lambda x: encode_label(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRh2U6N8OBeP",
        "outputId": "0f6cf5c0-88fb-4e4f-bd33-7c84b90659d1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['encoded']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZC-BrOP0qoc",
        "outputId": "81d3c738-6d85-46bc-b513-9436e634acf2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1114679353714016256    [[2, 3, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
              "1063020048816660480    [[4, 5, 6, 4, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
              "1108927368075374593    [[3, 7, 8, 9, 10, 11, 12, 13, 14, 3, 3, 7, 8, ...\n",
              "1114558534635618305    [[15, 16, 17, 18, 19, 3, 20, 15, 16, 17, 18, 1...\n",
              "1035252480215592966    [[21, 22, 23, 21, 22, 23, 0, 0, 0, 0, 0, 0, 0,...\n",
              "                                             ...                        \n",
              "1114170734472048640    [[83172, 17, 345, 470, 223, 67, 18676, 222, 83...\n",
              "1110368198786846720    [[3792, 3, 849, 15901, 3792, 3, 849, 15901, 0,...\n",
              "1106941858540851200    [[4, 3, 199, 2549, 4, 3, 199, 2549, 0, 0, 0, 0...\n",
              "1105268309233188865    [[470, 3, 387, 250, 114, 8575, 83173, 9603, 25...\n",
              "1114653514364530691    [[75, 3, 4896, 10143, 114, 207, 182, 75310, 24...\n",
              "Name: encoded, Length: 149823, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['length'] = df.tweet_text.str.len()"
      ],
      "metadata": {
        "id": "6oxQcalm--Rt"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df.length > 0]"
      ],
      "metadata": {
        "id": "CyFHGGqs_AFM"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = list(df['encoded'])\n",
        "y = list(df['targer_label'])\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "wuLsQGhTP1l3"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReviewsDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = X\n",
        "        self.y = Y\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return torch.from_numpy(self.X[idx][0].astype(np.int32)), self.y[idx], self.X[idx][1]"
      ],
      "metadata": {
        "id": "m6_2-OfeQIKH"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = ReviewsDataset(X_train, y_train)\n",
        "valid_ds = ReviewsDataset(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "lgu8OAcOQJVX"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model():\n",
        "    model = LSTM_variable_input(vocab_size, 50, 50)\n",
        "    epochs=30\n",
        "    lr=0.1\n",
        "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
        "    for i in range(epochs):\n",
        "        model.train()\n",
        "        sum_loss = 0.0\n",
        "        total = 0\n",
        "        for x, y, l in train_dl:\n",
        "            x = x.long()\n",
        "            y = y.long()\n",
        "            y_pred = model(x, l)\n",
        "            optimizer.zero_grad()\n",
        "            loss = F.cross_entropy(y_pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            sum_loss += loss.item()*y.shape[0]\n",
        "            total += y.shape[0]\n",
        "        val_loss, val_acc, val_rmse = validation_metrics(model, val_dl)\n",
        "        if i % 5 == 1:\n",
        "            print(\"train loss %.3f, val loss %.3f, val accuracy %.3f, and val rmse %.3f\" % (sum_loss/total, val_loss, val_acc, val_rmse))\n",
        "\n",
        "def validation_metrics (model, valid_dl):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    sum_loss = 0.0\n",
        "    sum_rmse = 0.0\n",
        "    for x, y, l in valid_dl:\n",
        "        x = x.long()\n",
        "        y = y.long()\n",
        "        y_hat = model(x, l)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        pred = torch.max(y_hat, 1)[1]\n",
        "        correct += (pred == y).float().sum()\n",
        "        total += y.shape[0]\n",
        "        sum_loss += loss.item()*y.shape[0]\n",
        "        sum_rmse += np.sqrt(mean_squared_error(pred, y.unsqueeze(-1)))*y.shape[0]\n",
        "    return sum_loss/total, correct/total, sum_rmse/total"
      ],
      "metadata": {
        "id": "7sQ1mKURQMJG"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 5000\n",
        "vocab_size = len(words)\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "val_dl = DataLoader(valid_ds, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "B46nuxzyQNTm"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM_variable_input(torch.nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, 5)\n",
        "        \n",
        "    def forward(self, x, s):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        x_pack = pack_padded_sequence(x, s, batch_first=True, enforce_sorted=False)\n",
        "        out_pack, (ht, ct) = self.lstm(x_pack)\n",
        "        out = self.linear(ht[-1])\n",
        "        return out"
      ],
      "metadata": {
        "id": "XmNN66imQP4X"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['length'] = df.tweet_text.str.len()\n"
      ],
      "metadata": {
        "id": "kYiX5LZm6knU"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gOU8qQ-HVTwY",
        "outputId": "9ee1d274-a099-403a-9e99-e95f0b9219da"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>labels</th>\n",
              "      <th>tweet_url</th>\n",
              "      <th>encoded</th>\n",
              "      <th>targer_label</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1114679353714016256</th>\n",
              "      <td>friskdontmiss nigga friskdontmiss nigga</td>\n",
              "      <td>[4, 1, 3]</td>\n",
              "      <td>https://twitter.com/user/status/11146793537140...</td>\n",
              "      <td>[[2, 3, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1063020048816660480</th>\n",
              "      <td>my horses retarded my horses retarded</td>\n",
              "      <td>[5, 5, 5]</td>\n",
              "      <td>https://twitter.com/user/status/10630200488166...</td>\n",
              "      <td>[[4, 5, 6, 4, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1108927368075374593</th>\n",
              "      <td>nigga on ma momma youngboy be spitting real sh...</td>\n",
              "      <td>[0, 0, 0]</td>\n",
              "      <td>https://twitter.com/user/status/11089273680753...</td>\n",
              "      <td>[[3, 7, 8, 9, 10, 11, 12, 13, 14, 3, 3, 7, 8, ...</td>\n",
              "      <td>0</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1114558534635618305</th>\n",
              "      <td>rt xxsugvngxx i ran holy nigga today rt xxsugv...</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "      <td>https://twitter.com/user/status/11145585346356...</td>\n",
              "      <td>[[15, 16, 17, 18, 19, 3, 20, 15, 16, 17, 18, 1...</td>\n",
              "      <td>0</td>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1035252480215592966</th>\n",
              "      <td>everybody calling nigger everybody calling nigger</td>\n",
              "      <td>[1, 0, 1]</td>\n",
              "      <td>https://twitter.com/user/status/10352524802155...</td>\n",
              "      <td>[[21, 22, 23, 21, 22, 23, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                            tweet_text  ... length\n",
              "1114679353714016256            friskdontmiss nigga friskdontmiss nigga  ...     39\n",
              "1063020048816660480              my horses retarded my horses retarded  ...     37\n",
              "1108927368075374593  nigga on ma momma youngboy be spitting real sh...  ...    109\n",
              "1114558534635618305  rt xxsugvngxx i ran holy nigga today rt xxsugv...  ...     73\n",
              "1035252480215592966  everybody calling nigger everybody calling nigger  ...     49\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df.length > 0]"
      ],
      "metadata": {
        "id": "ZY-muh6872cE"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df['tweet_text']:\n",
        "  if()"
      ],
      "metadata": {
        "id": "Swls0LyB-rc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(backend=\"torch\", num_workers=2)\n",
        "trainer.start()\n",
        "results = trainer.run(train_model)\n",
        "trainer.shutdown()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0B9RtRyQRWu",
        "outputId": "e0a0032f-e65d-4654-8b59-5bba3961fa4d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-12-09 02:18:44,258\tINFO trainer.py:172 -- Trainer logs will be logged in: /root/ray_results/train_2021-12-09_02-18-44\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=4124)\u001b[0m 2021-12-09 02:18:48,426\tINFO torch.py:67 -- Setting up process group for: env:// [rank=0, world_size=2]\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=4239)\u001b[0m 2021-12-09 02:18:48,410\tINFO torch.py:67 -- Setting up process group for: env:// [rank=1, world_size=2]\n",
            "2021-12-09 02:18:49,426\tINFO trainer.py:178 -- Run results will be logged in: /root/ray_results/train_2021-12-09_02-18-44/run_001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=4239)\u001b[0m train loss 0.481, val loss 0.519, val accuracy 0.760, and val rmse 0.490\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=4124)\u001b[0m train loss 0.497, val loss 0.539, val accuracy 0.753, and val rmse 0.497\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=4124)\u001b[0m train loss 0.342, val loss 0.632, val accuracy 0.731, and val rmse 0.519\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=4239)\u001b[0m train loss 0.328, val loss 0.646, val accuracy 0.737, and val rmse 0.513\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=4124)\u001b[0m train loss 0.301, val loss 0.694, val accuracy 0.732, and val rmse 0.517\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=4239)\u001b[0m train loss 0.291, val loss 0.702, val accuracy 0.730, and val rmse 0.520\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=4124)\u001b[0m train loss 0.292, val loss 0.731, val accuracy 0.731, and val rmse 0.518\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=4239)\u001b[0m train loss 0.277, val loss 0.730, val accuracy 0.736, and val rmse 0.513\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=4124)\u001b[0m train loss 0.285, val loss 0.735, val accuracy 0.731, and val rmse 0.519\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=4239)\u001b[0m train loss 0.273, val loss 0.737, val accuracy 0.731, and val rmse 0.519\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=4124)\u001b[0m train loss 0.284, val loss 0.773, val accuracy 0.732, and val rmse 0.518\n",
            "\u001b[2m\u001b[36m(BaseWorkerMixin pid=4239)\u001b[0m train loss 0.276, val loss 0.742, val accuracy 0.728, and val rmse 0.521\n"
          ]
        }
      ]
    }
  ]
}